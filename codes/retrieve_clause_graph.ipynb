{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import argparse\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "import GraphDB.utils as utils\n",
    "from GraphDB.LegalGraphDB import LegalGraphDB\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "# 로깅 설정 (INFO 레벨)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "path = os.getcwd()\n",
    "root_path = os.path.dirname(path)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# config.json 파일 경로를 절대 경로로 설정\n",
    "config_path = os.path.join(root_path, 'codes', 'configs', 'config_ra4.json')\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "print(config)\n",
    "dbms = LegalGraphDB(auradb=False, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vector search Library 설치 \n",
    "##### Graph Data Science -> 플러그인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072 3072 3072\n"
     ]
    }
   ],
   "source": [
    "QUERY_1 = \"증권신고서 또는 정정신고서 중 거짓의 기재 또는 표시가 있거나 중요사항이 기재 또는 표시되지 아니함으로써 투자자가 손해를 입은 경우 배상책임의 근거가 되는 조문은?\"\n",
    "QUERY_2 = \"회사채의 무보증 후순위사채 기업실사(Due Diligence)를 규정하고 있는데, 기업실사에서 회사의 기관 및 계열회사에 관한 사항은 어떤 것을 확인해야 하나?\"\n",
    "QUERY_3 = \"주식회사의 주주총회에서 주주의 의결권을 제한하는 경우에는 어떤 경우가 있나?\"\n",
    "\n",
    "embed_1 = utils.text_embed(QUERY_1, config[\"embedding_model\"])\n",
    "embed_2 = utils.text_embed(QUERY_2, config[\"embedding_model\"])\n",
    "embed_3 = utils.text_embed(QUERY_3, config[\"embedding_model\"])\n",
    "\n",
    "print(len(embed_1), len(embed_2), len(embed_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "증권신고서의 효력 발생기간은?\n",
      "Total time taken: 9.77 seconds\n",
      "\n",
      "\n",
      "========= Comparison of Hop-based and Vector-based Similarity Results =========\n",
      "length of top_k_results:  12\n",
      "\n",
      "####### idx: 0 #######\n",
      "## VECTOR ## : Labels: Clause_01_enforcement_main, Index: 제121조제2항, Similarity: 0.6657\n",
      "## HOP ## : hops : 0, Labels: Clause_01_enforcement_main, Index: 제121조제2항, Similarity: 0.6657\n",
      "\n",
      "####### idx: 1 #######\n",
      "## VECTOR ## : Labels: Clause_01_law_main, Index: 제120조제1항, Similarity: 0.6530\n",
      "## HOP ## : hops : 0, Labels: Clause_01_law_main, Index: 제120조제1항, Similarity: 0.6530\n",
      "\n",
      "####### idx: 2 #######\n",
      "## VECTOR ## : Labels: Clause_01_order_main, Index: 제12조제1항, Similarity: 0.6524\n",
      "## HOP ## : hops : 0, Labels: Clause_01_order_main, Index: 제12조제1항, Similarity: 0.6524\n",
      "\n",
      "####### idx: 3 #######\n",
      "## VECTOR ## : Labels: Clause_01_order_main, Index: 제12조제4항, Similarity: 0.6448\n",
      "## HOP ## : hops : 0, Labels: Clause_01_order_main, Index: 제12조제4항, Similarity: 0.6448\n",
      "\n",
      "####### idx: 4 #######\n",
      "## VECTOR ## : Labels: Clause_01_law_main, Index: 제101조제6항, Similarity: 0.6232\n",
      "## HOP ## : hops : 0, Labels: Clause_01_law_main, Index: 제101조제6항, Similarity: 0.6232\n",
      "\n",
      "####### idx: 5 #######\n",
      "## VECTOR ## : Labels: Clause_01_order_main, Index: 제12조제3항, Similarity: 0.6143\n",
      "## HOP ## : hops : 1, Labels: Clause_01_order_main, Index: 제12조제3항, Similarity: 0.6143\n",
      "\n",
      "####### idx: 6 #######\n",
      "## VECTOR ## : Labels: Clause_01_order_main, Index: 제12조제2항, Similarity: 0.5918\n",
      "## HOP ## : hops : 1, Labels: Clause_01_order_main, Index: 제12조제2항, Similarity: 0.5918\n",
      "\n",
      "####### idx: 7 #######\n",
      "## VECTOR ## : Labels: Clause_01_law_main, Index: 제128조, Similarity: 0.5789\n",
      "## HOP ## : hops : 1, Labels: Clause_01_law_main, Index: 제122조제1항, Similarity: 0.5188\n",
      "\n",
      "####### idx: 8 #######\n",
      "## VECTOR ## : Labels: Clause_01_law_main, Index: 제122조제2항, Similarity: 0.5786\n",
      "## HOP ## : hops : 1, Labels: Clause_01_law_main, Index: 제159조제1항, Similarity: 0.5133\n",
      "\n",
      "####### idx: 9 #######\n",
      "## VECTOR ## : Labels: Clause_01_enforcement_main, Index: 제121조제4항, Similarity: 0.5773\n",
      "## HOP ## : hops : 1, Labels: Clause_01_law_main, Index: 제119조제2항, Similarity: 0.4623\n",
      "\n",
      "####### idx: 10 #######\n",
      "## VECTOR ## : Labels: Clause_01_law_main, Index: 제173조제2항, Similarity: 0.5686\n",
      "## HOP ## : hops : 1, Labels: Clause_01_law_main, Index: 제120조제2항, Similarity: 0.4560\n",
      "\n",
      "####### idx: 11 #######\n",
      "## VECTOR ## : Labels: Clause_01_law_main, Index: 제144조, Similarity: 0.5678\n",
      "## HOP ## : hops : 1, Labels: Clause_01_law_main, Index: 제119조제1항, Similarity: 0.4396\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Neo4j 연결 설정\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "user = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "QUERY= \"증권신고서의 효력 발생기간은?\"\n",
    "ANSWER  = \"\"\"\n",
    "증권신고서의 효력 발생 기간은 보통 접수일로부터 15일 후에 발생합니다. 그러나 금융감독원이 보완 요청을 하거나 심사가 필요할 경우 효력 발생이 연기될 수 있습니다. 아래는 구체적인 내용입니다:\n",
    "\n",
    "기본 규정:\n",
    "\n",
    "증권신고서는 제출 후 15일이 지나면 효력이 발생합니다.\n",
    "만약 증권의 종류에 따라 법령이 달리 규정되어 있다면 해당 규정이 우선 적용됩니다.\n",
    "보완 요청 시:\n",
    "\n",
    "금융감독원이 증권신고서에 대해 보완을 요청하면, 효력 발생은 그 보완서가 제출된 날부터 다시 15일이 경과한 후로 연기됩니다.\n",
    "즉시 효력 발생 요건:\n",
    "\n",
    "일부 발행(예: 유상증자)의 경우 신고서 제출 후 15일이 아닌 즉시 효력이 발생하도록 하는 절차가 존재합니다. 이러한 경우는 발행기업의 신속한 자본 조달이 필요한 상황 등을 고려한 예외 조치입니다.\n",
    "따라서 기본적으로는 15일이 표준이지만, 상황에 따라 효력 발생 시점이 달라질 수 있습니다.\n",
    "\"\"\"\n",
    "\n",
    "QUERY_EMB = utils.text_embed(QUERY, config[\"embedding_model\"])\n",
    "ANSWER_EMB = utils.text_embed(ANSWER, config[\"embedding_model\"])\n",
    "\n",
    "print(QUERY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neo4j에서 쿼리 벡터와 유사한 노드 검색\n",
    "def find_similar_nodes(query_embedding_vec, driver, config):\n",
    "    retrieved_nodes = []  \n",
    "    top_k = config.get(\"top_k\", 5)  # config에서 top_k 값을 가져오며 기본값을 5로 설정\n",
    "    query = f\"\"\"\n",
    "    WITH $embedding AS query_embedding_vec\n",
    "    MATCH (n)\n",
    "    WHERE ANY(label IN labels(n) WHERE label STARTS WITH 'Clause')\n",
    "    WITH n, gds.similarity.cosine(n.embedding, query_embedding_vec) AS similarity\n",
    "    ORDER BY similarity DESC\n",
    "    LIMIT {top_k}\n",
    "    RETURN n, similarity\n",
    "    \"\"\"\n",
    "    with driver.session(database=config[\"database\"]) as session:\n",
    "        result = session.run(query, embedding=query_embedding_vec)  \n",
    "        for record in result:\n",
    "            node = record['n']\n",
    "            node_id = node.element_id  # 노드의 고유 식별자를 사용하여 중복 방지\n",
    "            similarity = record['similarity']\n",
    "            labels = list(node.labels)[0] if len(node.labels) > 0 else \"Unknown\"  # 리스트 형태에서 첫 번째 레이블만 추출\n",
    "            retrieved_nodes.append({\n",
    "                'node_id': node_id,\n",
    "                'index': node.get('law_index'),\n",
    "                'labels': labels,\n",
    "                'text': node.get('text'),\n",
    "                'similarity': similarity,\n",
    "                'hop': 0  # Top K 노드는 hop 0으로 표시\n",
    "            })\n",
    "    \n",
    "    return retrieved_nodes\n",
    "\n",
    "# Neo4j에서 유사한 노드를 검색하고 refers_to 엣지를 따라 연결된 노드를 탐색하는 함수\n",
    "def find_related_nodes_with_keywords(query_embedding_vec, keywords, config, hop=1):\n",
    "    \n",
    "    # Top K 유사한 노드 검색\n",
    "    top_k_nodes = find_similar_nodes(query_embedding_vec, driver, config)\n",
    "\n",
    "    # Top K 노드의 element_id를 추출하여 이웃 노드 탐색 시작\n",
    "    top_k_element_ids = [node['node_id'] for node in top_k_nodes]\n",
    "    visited_nodes = set(top_k_element_ids)  # 중복된 노드 방문 방지\n",
    "\n",
    "    # Top K 노드를 관련 문서 집합에 추가\n",
    "    related_documents = set()\n",
    "    for node in top_k_nodes:\n",
    "        related_documents.add(frozenset(node.items()))  \n",
    "\n",
    "    def recursive_search(element_ids, current_hop):\n",
    "        if current_hop > hop:\n",
    "            return set()  \n",
    "\n",
    "        related_nodes = set()  \n",
    "        for element_id in element_ids:\n",
    "            query = \"\"\"\n",
    "            MATCH (n)-[:refers_to]->(neighbor)\n",
    "            WHERE elementId(n) = $element_id\n",
    "            RETURN neighbor\n",
    "            \"\"\"\n",
    "\n",
    "            with driver.session(database=config[\"database\"]) as session:\n",
    "                result = session.run(query, element_id=element_id)\n",
    "                for record in result:\n",
    "                    neighbor = record['neighbor']\n",
    "                    neighbor_id = neighbor.element_id  \n",
    "                    \n",
    "                    # 이미 방문한 노드 제외 \n",
    "                    if neighbor_id in visited_nodes:\n",
    "                        continue\n",
    "\n",
    "                    visited_nodes.add(neighbor_id)\n",
    "                    labels = list(neighbor.labels)[0] if len(neighbor.labels) > 0 else \"Unknown\"\n",
    "\n",
    "                    # 이웃 노드의 embedding을 가져와 유사도 계산\n",
    "                    neighbor_embedding = np.array(neighbor['embedding'])\n",
    "                    similarity = cosine_similarity([query_embedding_vec], [neighbor_embedding])[0][0]\n",
    "                    \n",
    "                    # 유사도와 키워드 조건을 만족하는지 확인\n",
    "                    if similarity >= config['threshold']:\n",
    "                        related_node = {\n",
    "                            'node_id': neighbor_id,\n",
    "                            'index': neighbor.get('law_index'),\n",
    "                            'labels': labels,\n",
    "                            'text': neighbor.get('text'),\n",
    "                            'similarity': similarity,\n",
    "                            'hop': current_hop\n",
    "                        }\n",
    "                        related_nodes.add(frozenset(related_node.items()))  # frozenset으로 변환 후 추가하여 중복 방지\n",
    "                        \n",
    "                        # 재귀적으로 연결된 노드를 탐색 (hop을 올바르게 증가시켜 호출)\n",
    "                        related_nodes.update(recursive_search([neighbor_id], current_hop + 1))\n",
    "        return related_nodes\n",
    "\n",
    "    # 이웃 노드를 탐색하고 유사도와 키워드 필터링 적용\n",
    "    for element_id in top_k_element_ids:\n",
    "        related_documents.update(recursive_search([element_id], current_hop=1))\n",
    "\n",
    "    related_documents = [dict(doc) for doc in related_documents]  # frozenset을 dict로 변환하여 리스트로 정렬\n",
    "    related_documents = sorted(related_documents, key=lambda x: x['similarity'], reverse=True)\n",
    "\n",
    "    return top_k_nodes, related_documents\n",
    "\n",
    "keywords = ['증권신고서', '효력 발생기간']\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# 단순 벡터 유사도 검색 결과와 hop 검색 결과를 얻음\n",
    "top_k_results, related_docs = find_related_nodes_with_keywords(QUERY_EMB, keywords, config, hop=5)\n",
    "answer_top_k_results, answer_related_docs = find_related_nodes_with_keywords(ANSWER_EMB, keywords, config, hop=5)\n",
    "# hop 검색 결과의 길이를 config에 설정\n",
    "config['top_k'] = len(related_docs)\n",
    "\n",
    "# 수정된 top_k로 다시 단순 벡터 유사도 검색\n",
    "top_k_results = find_similar_nodes(QUERY_EMB, driver, config)\n",
    "# 수정된 top_k로 다시 단순 벡터 유사도 검색\n",
    "answer_top_k_results = find_similar_nodes(ANSWER_EMB, driver, config)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total time taken\n",
    "total_time = end_time - start_time\n",
    "\n",
    "\n",
    "print(f\"Total time taken: {total_time:.2f} seconds\\n\")\n",
    "\n",
    "# 인덱스별로 Top-K 검색 결과와 Hop 검색 결과를 한 번에 출력\n",
    "print(\"\\n========= Comparison of Hop-based and Vector-based Similarity Results =========\")\n",
    "max_length = min(len(top_k_results), len(related_docs))\n",
    "print(\"length of top_k_results: \", len(top_k_results))\n",
    "\n",
    "for idx in range(max_length):\n",
    "    top_k_node = top_k_results[idx]\n",
    "    related_doc = related_docs[idx]\n",
    "    \n",
    "    print(f\"\\n####### idx: {idx} #######\")\n",
    "    print(f\"## VECTOR ## : Labels: {top_k_node['labels']}, Index: {top_k_node['index']}, Similarity: {top_k_node['similarity']:.4f}\")\n",
    "    print(f\"## HOP ## : hops : {related_doc['hop']}, Labels: {related_doc['labels']}, Index: {related_doc['index']}, Similarity: {related_doc['similarity']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../data/graph/retrieval/hop-retrieve_results.json\", \"w\") as f:\n",
    "    json.dump(related_docs, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "# top_k_results, answer_top_k_results 를 json 형태 저장 \n",
    "with open(\"../data/graph/retrieval/top_k_results.json\", \"w\") as f:\n",
    "    json.dump(top_k_results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(\"../data/graph/retrieval/answer_top_k_results.json\", \"w\") as f:\n",
    "    json.dump(answer_top_k_results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "with open(\"../data/graph/retrieval/answer_related_docs.json\", \"w\") as f:\n",
    "    json.dump(answer_related_docs, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####### Node in Vector-based Only #######\n",
      "idx : 60, Labels: Clause_01_enforcement_main, Index: 제176조의15제4항, Similarity: 0.4775\n",
      "idx : 62, Labels: Clause_01_enforcement_main, Index: 제92조제4항, Similarity: 0.4772\n",
      "idx : 63, Labels: Clause_01_enforcement_main, Index: 제131조제4항, Similarity: 0.4754\n",
      "idx : 64, Labels: Clause_01_order_main, Index: 제2조, Similarity: 0.4751\n",
      "idx : 66, Labels: Clause_01_law_main, Index: 제159조제3항, Similarity: 0.4730\n",
      "idx : 67, Labels: Clause_01_law_main, Index: 제112조제6항, Similarity: 0.4726\n",
      "idx : 68, Labels: Clause_01_enforcement_main, Index: 제324조의9제3항, Similarity: 0.4718\n",
      "idx : 69, Labels: Clause_01_law_main, Index: 제165조제4항, Similarity: 0.4717\n",
      "idx : 70, Labels: Clause_01_law_main, Index: 제33조제2항, Similarity: 0.4709\n",
      "idx : 71, Labels: Clause_01_enforcement_main, Index: 제369조제4항, Similarity: 0.4691\n",
      "idx : 72, Labels: Clause_01_law_main, Index: 제258조제4항, Similarity: 0.4687\n",
      "idx : 73, Labels: Clause_01_law_main, Index: 제254조제4항, Similarity: 0.4686\n",
      "idx : 74, Labels: Clause_01_law_main, Index: 제263조제4항, Similarity: 0.4681\n",
      "idx : 75, Labels: Clause_01_law_main, Index: 제147조제4항, Similarity: 0.4676\n",
      "idx : 76, Labels: Clause_01_enforcement_main, Index: 제101조제1항, Similarity: 0.4675\n",
      "idx : 77, Labels: Clause_01_enforcement_main, Index: 제120조제1항, Similarity: 0.4671\n",
      "idx : 79, Labels: Clause_01_law_main, Index: 제162조제5항, Similarity: 0.4665\n",
      "idx : 80, Labels: Clause_01_law_main, Index: 제117조의10제8항, Similarity: 0.4654\n",
      "idx : 82, Labels: Clause_01_order_main, Index: 제12조제5항, Similarity: 0.4645\n",
      "idx : 83, Labels: Clause_01_law_main, Index: 제240조제3항, Similarity: 0.4643\n",
      "idx : 84, Labels: Clause_01_law_main, Index: 제248조제2항, Similarity: 0.4642\n",
      "idx : 85, Labels: Clause_01_law_main, Index: 제365조제4항, Similarity: 0.4634\n",
      "idx : 86, Labels: Clause_01_law_main, Index: 제145조, Similarity: 0.4632\n",
      "idx : 88, Labels: Clause_01_enforcement_main, Index: 제221조제3항, Similarity: 0.4625\n",
      "idx : 89, Labels: Clause_01_enforcement_main, Index: 제176조의13제3항, Similarity: 0.4617\n",
      "idx : 90, Labels: Clause_01_enforcement_main, Index: 제176조의2제5항, Similarity: 0.4616\n",
      "idx : 91, Labels: Clause_01_enforcement_main, Index: 제317조의2, Similarity: 0.4612\n",
      "idx : 92, Labels: Clause_01_order_main, Index: 제36조의2, Similarity: 0.4610\n",
      "\n",
      "####### Node in Hop-based Only #######\n",
      "idx : 65, Labels: Clause_01_law_main, Index: 제160조, Similarity: 0.4568\n",
      "idx : 66, Labels: Clause_01_law_main, Index: 제122조제4항, Similarity: 0.4553\n",
      "idx : 67, Labels: Clause_01_law_main, Index: 제120조제2항, Similarity: 0.4541\n",
      "idx : 68, Labels: Clause_01_law_main, Index: 제119조제3항, Similarity: 0.4536\n",
      "idx : 69, Labels: Clause_01_law_main, Index: 제119조제6항, Similarity: 0.4536\n",
      "idx : 70, Labels: Clause_01_law_main, Index: 제117조의10제4항, Similarity: 0.4505\n",
      "idx : 71, Labels: Clause_01_law_main, Index: 제101조제7항, Similarity: 0.4484\n",
      "idx : 72, Labels: Clause_01_law_main, Index: 제121조제2항, Similarity: 0.4472\n",
      "idx : 73, Labels: Clause_01_law_main, Index: 제119조제1항, Similarity: 0.4422\n",
      "idx : 74, Labels: Clause_01_law_main, Index: 제119조의2제2항, Similarity: 0.4419\n",
      "idx : 75, Labels: Clause_01_law_main, Index: 제150조제3항, Similarity: 0.4405\n",
      "idx : 76, Labels: Clause_01_law_main, Index: 제150조제1항, Similarity: 0.4367\n",
      "idx : 77, Labels: Clause_01_law_main, Index: 제150조제2항, Similarity: 0.4363\n",
      "idx : 78, Labels: Clause_01_law_main, Index: 제138조제2항, Similarity: 0.4362\n",
      "idx : 79, Labels: Clause_01_law_main, Index: 제130조제1항, Similarity: 0.4357\n",
      "idx : 80, Labels: Clause_01_law_main, Index: 제142조제1항, Similarity: 0.4291\n",
      "idx : 81, Labels: Clause_01_law_main, Index: 제117조의12제1항, Similarity: 0.4271\n",
      "idx : 82, Labels: Clause_01_law_main, Index: 제161조제1항, Similarity: 0.4263\n",
      "idx : 83, Labels: Clause_01_law_main, Index: 제123조제3항, Similarity: 0.4261\n",
      "idx : 84, Labels: Clause_01_law_main, Index: 제161조제5항, Similarity: 0.4243\n",
      "idx : 85, Labels: Clause_01_law_main, Index: 제123조제1항, Similarity: 0.4238\n",
      "idx : 86, Labels: Clause_01_law_main, Index: 제119조제4항, Similarity: 0.4227\n",
      "idx : 87, Labels: Clause_01_law_main, Index: 제136조제3항, Similarity: 0.4207\n",
      "idx : 88, Labels: Clause_01_law_main, Index: 제180조의5제1항, Similarity: 0.4149\n",
      "idx : 89, Labels: Clause_01_law_main, Index: 제436조제1항, Similarity: 0.4139\n",
      "idx : 90, Labels: Clause_01_law_main, Index: 제139조제2항, Similarity: 0.4047\n",
      "idx : 91, Labels: Clause_01_law_main, Index: 제101조제2항, Similarity: 0.4030\n",
      "idx : 92, Labels: Clause_01_law_main, Index: 제165조의5제4항, Similarity: 0.4014\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vector_node_ids = set([node['node_id'] for node in top_k_results])\n",
    "hop_node_ids = set([doc['node_id'] for doc in related_docs])\n",
    "\n",
    "# 벡터 기반 검색 결과에는 있지만 hop 기반 검색 결과에는 없는 노드\n",
    "only_in_vector = vector_node_ids - hop_node_ids\n",
    "print(f\"\\n####### Node in Vector-based Only #######\")\n",
    "for idx, node in enumerate(top_k_results):\n",
    "    if node['node_id'] in only_in_vector:\n",
    "        \n",
    "        print(f\"idx : {idx}, Labels: {node['labels']}, Index: {node['index']}, Similarity: {node['similarity']:.4f}\")\n",
    "\n",
    "\n",
    "print(f\"\\n####### Node in Hop-based Only #######\")\n",
    "# hop 기반 검색 결과에는 있지만 벡터 기반 검색 결과에는 없는 노드\n",
    "only_in_hop = hop_node_ids - vector_node_ids\n",
    "for idx, doc in enumerate(related_docs):\n",
    "    if doc['node_id'] in only_in_hop:\n",
    "        \n",
    "        print(f\"idx : {idx}, Labels: {doc['labels']}, Index: {doc['index']}, Similarity: {doc['similarity']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 4, column: 24, offset: 101} for query: \"\\n                MATCH (n)\\n                WHERE n.type STARTS WITH 'Clause_'\\n                RETURN id(n) AS nodeId, n.embedding AS embedding\\n                \"\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: type)} {position: line: 3, column: 25, offset: 51} for query: \"\\n                MATCH (n)\\n                WHERE n.type STARTS WITH 'Clause_'\\n                RETURN id(n) AS nodeId, n.embedding AS embedding\\n                \"\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: embedding)} {position: line: 4, column: 43, offset: 120} for query: \"\\n                MATCH (n)\\n                WHERE n.type STARTS WITH 'Clause_'\\n                RETURN id(n) AS nodeId, n.embedding AS embedding\\n                \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## query : 증권신고서 제출기한 연장에 대한 법적 책임은 무엇인가요?, query_keywords : ['증권신고서', '제출기한 연장', '법적 책임'], len(query_embedding_vector) : 3072\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m query_keywords \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mextract_keyword(text\u001b[38;5;241m=\u001b[39mquery, prompt_path \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_keyword_prompt_path\u001b[39m\u001b[38;5;124m\"\u001b[39m],keyword_model \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## query : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, query_keywords : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_keywords\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, len(query_embedding_vector) : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(query_embedding_vector)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m retrieved_documents \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_related_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdbms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdbms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_vec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquery_embedding_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mquery_keywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(retrieved_documents)\n\u001b[0;32m     11\u001b[0m reranked_documents \u001b[38;5;241m=\u001b[39m rerank_documents(retrieved_documents)\n",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m, in \u001b[0;36mretrieve_related_documents\u001b[1;34m(dbms, config, embed_vec, keywords, hop)\u001b[0m\n\u001b[0;32m     19\u001b[0m                 related_nodes\u001b[38;5;241m.\u001b[39mextend(recursive_retrieve([neighbor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m]], current_hop \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m related_nodes\n\u001b[1;32m---> 22\u001b[0m initial_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_k_similar_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdbms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_clause_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recursive_retrieve(initial_nodes, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mget_top_k_similar_nodes\u001b[1;34m(target_vector, nodes_embeddings, K)\u001b[0m\n\u001b[0;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([node[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes_embeddings])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 코사인 유사도 계산\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_vector\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 유사도에 따라 정렬하고 상위 K개 노드의 id 반환\u001b[39;00m\n\u001b[0;32m     11\u001b[0m top_k_indices \u001b[38;5;241m=\u001b[39m similarities\u001b[38;5;241m.\u001b[39margsort()[\u001b[38;5;241m-\u001b[39mK:][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Shic\\anaconda3\\envs\\new_neo4j\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Shic\\anaconda3\\envs\\new_neo4j\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1679\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m \n\u001b[0;32m   1637\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\Shic\\anaconda3\\envs\\new_neo4j\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:194\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    186\u001b[0m         X,\n\u001b[0;32m    187\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    193\u001b[0m     )\n\u001b[1;32m--> 194\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Shic\\anaconda3\\envs\\new_neo4j\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "# query -> vector embedding , keyword 추출 \n",
    "query = \"증권신고서 제출기한 연장에 대한 법적 책임은 무엇인가요?\"\n",
    "query_embedding_vector = utils.text_embed(text = query, embed_model = config.get('embedding_model') )\n",
    "query_keywords = utils.extract_keyword(text=query, prompt_path = config[\"query_keyword_prompt_path\"],keyword_model = config[\"model\"])\n",
    "print(f\"## query : {query}, query_keywords : {query_keywords}, len(query_embedding_vector) : {len(query_embedding_vector)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hop 별로  정렬하기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM based answer (No document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM based answer 산출하고 retrieve 해보기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .py 위한 재료 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(config: Dict):\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    g = parser.add_argument_group(\"Settings\")\n",
    "    g.add_argument(\"--topK\", type=int, default=10, help=\"Number of top related documents to retrieve\")\n",
    "    g.add_argument(\"--threshold\", type=float, default=0.5, help=\"Threshold for relatedness score\")\n",
    "    g.add_argument(\"--output\", type=str, default=\"C:/Users/Shic/development/GIB/legal_graph-main/data/graph/clause/retrieve/related_documents.json\", help=\"Output file path\")\n",
    "    g.add_argument(\"--query\" , type=str, default=\"C:/Users/Shic/development/GIB/legal_graph-main/data/graph/clause/retrieve/query.txt\", help=\"Query file path\")\n",
    "    \n",
    "\n",
    "    args = parser.parse_args()\n",
    "    database = config.get(\"database\")\n",
    "\n",
    "    \n",
    "    dbms = LegalGraphDB(auradb=False, config=config)\n",
    "\n",
    "    # query -> vector embedding , keyword 추출 \n",
    "    query_embedding_vector = utils.text_embed(config, args.query)\n",
    "    query_keywords = extract_keyword(config, args.query)\n",
    "    \n",
    "    # 전체 node 중 query와 가장 유사한 topK개의 node_id를 반환\n",
    "    retrieved_nodes = retrieve_related_documents(dbms, config , embed_vec = query_embedding_vector, keyword = query_keywords) \n",
    "\n",
    "    \n",
    "    \n",
    "    # topk 노드와 간선으로 연결된 node 중 (유사도가 threshold 이상) & (query에서 추출한 keyword를 포함하고 있으면서 ) hop1의 node_id를 반환\n",
    "    # hopH까지 반복 \n",
    "    # 반환된 document 에서 reranking -> 키워드 포함 / 유사도 / 홉 수 등 고려하여 가중치 부여 \n",
    "    # reranking된 노드를 json으로 저장 \n",
    "    # ex. {query : str , retrievedDocuments: {node_id : {keyword : [keyword1, keyword2, ...], similarity : 0.8, hop : 2}}} \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # config.json 파일 경로를 절대 경로로 설정\n",
    "    config_path = os.path.join(root_path, 'codes', 'configs', 'config.json')\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    main(config=config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo4j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
